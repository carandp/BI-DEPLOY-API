{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar librerías para pipeline\n",
    "A continuación se importan las librerías para la construcción del pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRegressionPipeline(BaseEstimator, RegressorMixin):\n",
    "    # Inicia el pipeline con los pasos necesarios\n",
    "    def __init__(self):\n",
    "        self.pipeline = Pipeline([\n",
    "            # Selecciona las columnas categóricas y las vectoriza con OneHotEncoder\n",
    "            ('onehot', ColumnTransformer(\n",
    "                transformers=[('onehot', OneHotEncoder(), ['class'])],\n",
    "                remainder='passthrough')),\n",
    "            # Escala las columnas numéricas con StandardScaler y añade polinomios de grado 2\n",
    "            ('poly', Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('poly', PolynomialFeatures(degree=2, include_bias=False))\n",
    "            ])),\n",
    "            # Crea un modelo de regresión lineal\n",
    "            ('regressor', LinearRegression())\n",
    "        ])\n",
    "        \n",
    "        # Indica si el modelo ha sido entrenado\n",
    "        self.is_fitted_ = False\n",
    "    \n",
    "    # Limpia los datos y los prepara para el entrenamiento\n",
    "    def _clean_data(self, df):\n",
    "        df_clean = df.copy()\n",
    "        \n",
    "        if 'redshift' not in df_clean.columns:\n",
    "            print(\"The 'redshift' column is missing.\")\n",
    "            return None\n",
    "        \n",
    "        num_features = [\"ra\", \"dec\", \"u\", \"r\", \"field\", \"mjd\", \"rowv\", \"colv\"]\n",
    "        \n",
    "        # Elimina los outliers\n",
    "        for col in num_features:\n",
    "            q1 = df_clean[col].quantile(0.25)\n",
    "            q3 = df_clean[col].quantile(0.75)\n",
    "            riq = q3 - q1\n",
    "            lower_bound = q1 - 3 * riq\n",
    "            upper_bound = q3 + 3 * riq\n",
    "            df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "        \n",
    "        # Elimina duplicados\n",
    "        df_clean = df_clean.drop_duplicates()\n",
    "        \n",
    "        # Corrige los valores atípicos en la variable categórica 'class'\n",
    "        df_clean[\"class\"] = df_clean[\"class\"].replace({\"S\": \"STAR\", \"G\": \"GALAXY\", \"Q\": \"QSO\"})\n",
    "        df_clean = df_clean[df_clean[\"class\"].isin([\"STAR\", \"GALAXY\", \"QSO\"])]\n",
    "        \n",
    "        # Quita los registros que tengan un puntaje menor a 0.5 y que no estén limpios\n",
    "        df_clean = df_clean[df_clean[\"score\"] >= 0.5]\n",
    "        df_clean = df_clean[df_clean[\"clean\"] != 0]\n",
    "        \n",
    "        return df_clean\n",
    "    \n",
    "    # Limpia los datos y los prepara para la predicción\n",
    "    def _clean_data_predict(self, df):\n",
    "        df_clean = df.copy()\n",
    "        \n",
    "        # Corrige los valores atípicos en la variable categórica 'class'\n",
    "        df_clean[\"class\"] = df_clean[\"class\"].replace({\"S\": \"STAR\", \"G\": \"GALAXY\", \"Q\": \"QSO\"})\n",
    "        df_clean = df_clean[df_clean[\"class\"].isin([\"STAR\", \"GALAXY\", \"QSO\"])]\n",
    "        \n",
    "        return df_clean\n",
    "\n",
    "    # Entrena el modelo\n",
    "    def fit(self, X, y=None):\n",
    "        df = X.copy()\n",
    "        \n",
    "        # Limpia los datos con la función previa\n",
    "        df_clean = self._clean_data(df)\n",
    "        \n",
    "        # Obtiene la variable objetivo y las características\n",
    "        y_clean = df_clean['redshift']\n",
    "        feature_cols = [\"ra\", \"dec\", \"u\", \"r\", \"field\", \"class\", \"mjd\", \"rowv\", \"colv\"]\n",
    "        X_features = df_clean[feature_cols]\n",
    "        \n",
    "        # Divide los datos en entrenamiento y prueba de 70% y 30% respectivamente\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_features, y_clean, test_size=0.3, random_state=1\n",
    "        )\n",
    "        \n",
    "        # Entrena el modelo\n",
    "        self.pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Predice los valores de entrenamiento y prueba\n",
    "        y_train_pred = self.pipeline.predict(X_train)\n",
    "        y_test_pred  = self.pipeline.predict(X_test)\n",
    "        \n",
    "        # Muestra estadísticas de prueba del modelo\n",
    "        print(\"====== Model Performance ======\")\n",
    "        print(\"Train MAE:\", mean_absolute_error(y_train, y_train_pred))\n",
    "        print(\"Test MAE:\", mean_absolute_error(y_test, y_test_pred))\n",
    "        print(\"Train RMSE:\", np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "        print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "        print(\"Train R²:\", r2_score(y_train, y_train_pred))\n",
    "        print(\"Test R²:\", r2_score(y_test, y_test_pred))\n",
    "        print(\"===============================\\n\")\n",
    "        \n",
    "        # Guarda el modelo entrenado y actualiza el estado de is_fitted_\n",
    "        self.pipeline.fit(X_features, y_clean)\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    # Predice los valores de la variable objetivo con el modelo entrenado\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # Verifica si el modelo ha sido entrenado\n",
    "        if not self.is_fitted_:\n",
    "            print(\"You must fit the model before predicting.\")\n",
    "            return None\n",
    "        \n",
    "        df = X.copy()\n",
    "        feature_cols = [\"ra\", \"dec\", \"u\", \"r\", \"field\", \"class\", \"mjd\", \"rowv\", \"colv\"]\n",
    "        \n",
    "        # Limpia los datos con la función previa para predicción \n",
    "        clean_df = self._clean_data_predict(df)\n",
    "        \n",
    "        # Filtra y selecciona las columnas usadas para entrenar el modelo\n",
    "        X_features = clean_df[feature_cols]\n",
    "        \n",
    "        # Predice el valor de la variable objetivo\n",
    "        return self.pipeline.predict(X_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga y exportación del pipeline\n",
    "\n",
    "El código de carga y exportación del pipeline se puede observar el archivo DumpModel.py de la carpeta app.\n",
    "Si se quiere ejecutar hay que crear el joblib desde ahí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Model Performance ======\n",
      "Train MAE: 0.058293365344135144\n",
      "Test MAE: 0.054523501873186456\n",
      "Train RMSE: 0.17727193589929297\n",
      "Test RMSE: 0.1656064661549114\n",
      "Train R²: 0.8133038383130855\n",
      "Test R²: 0.8089601577699788\n",
      "===============================\n",
      "\n",
      "Modelo exportado como model.joblib a la carpeta de app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from app.DumpModel import dump_model\n",
    "# dump_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
